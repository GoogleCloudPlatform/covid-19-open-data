# Copyright 2020 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Age stratified pipeline configuration

schema:
  date: str
  key: str
  new_confirmed_age_00: int
  new_confirmed_age_01: int
  new_confirmed_age_02: int
  new_confirmed_age_03: int
  new_confirmed_age_04: int
  new_confirmed_age_05: int
  new_confirmed_age_06: int
  new_confirmed_age_07: int
  new_confirmed_age_08: int
  new_confirmed_age_09: int
  total_confirmed_age_00: int
  total_confirmed_age_01: int
  total_confirmed_age_02: int
  total_confirmed_age_03: int
  total_confirmed_age_04: int
  total_confirmed_age_05: int
  total_confirmed_age_06: int
  total_confirmed_age_07: int
  total_confirmed_age_08: int
  total_confirmed_age_09: int
  new_deceased_age_00: int
  new_deceased_age_01: int
  new_deceased_age_02: int
  new_deceased_age_03: int
  new_deceased_age_04: int
  new_deceased_age_05: int
  new_deceased_age_06: int
  new_deceased_age_07: int
  new_deceased_age_08: int
  new_deceased_age_09: int
  total_deceased_age_00: int
  total_deceased_age_01: int
  total_deceased_age_02: int
  total_deceased_age_03: int
  total_deceased_age_04: int
  total_deceased_age_05: int
  total_deceased_age_06: int
  total_deceased_age_07: int
  total_deceased_age_08: int
  total_deceased_age_09: int
  new_recovered_age_00: int
  new_recovered_age_01: int
  new_recovered_age_02: int
  new_recovered_age_03: int
  new_recovered_age_04: int
  new_recovered_age_05: int
  new_recovered_age_06: int
  new_recovered_age_07: int
  new_recovered_age_08: int
  new_recovered_age_09: int
  total_recovered_age_00: int
  total_recovered_age_01: int
  total_recovered_age_02: int
  total_recovered_age_03: int
  total_recovered_age_04: int
  total_recovered_age_05: int
  total_recovered_age_06: int
  total_recovered_age_07: int
  total_recovered_age_08: int
  total_recovered_age_09: int
  new_tested_age_00: int
  new_tested_age_01: int
  new_tested_age_02: int
  new_tested_age_03: int
  new_tested_age_04: int
  new_tested_age_05: int
  new_tested_age_06: int
  new_tested_age_07: int
  new_tested_age_08: int
  new_tested_age_09: int
  total_tested_age_00: int
  total_tested_age_01: int
  total_tested_age_02: int
  total_tested_age_03: int
  total_tested_age_04: int
  total_tested_age_05: int
  total_tested_age_06: int
  total_tested_age_07: int
  total_tested_age_08: int
  total_tested_age_09: int
  new_hospitalized_age_00: int
  new_hospitalized_age_01: int
  new_hospitalized_age_02: int
  new_hospitalized_age_03: int
  new_hospitalized_age_04: int
  new_hospitalized_age_05: int
  new_hospitalized_age_06: int
  new_hospitalized_age_07: int
  new_hospitalized_age_08: int
  new_hospitalized_age_09: int
  total_hospitalized_age_00: int
  total_hospitalized_age_01: int
  total_hospitalized_age_02: int
  total_hospitalized_age_03: int
  total_hospitalized_age_04: int
  total_hospitalized_age_05: int
  total_hospitalized_age_06: int
  total_hospitalized_age_07: int
  total_hospitalized_age_08: int
  total_hospitalized_age_09: int
  current_hospitalized_age_00: int
  current_hospitalized_age_01: int
  current_hospitalized_age_02: int
  current_hospitalized_age_03: int
  current_hospitalized_age_04: int
  current_hospitalized_age_05: int
  current_hospitalized_age_06: int
  current_hospitalized_age_07: int
  current_hospitalized_age_08: int
  current_hospitalized_age_09: int
  new_intensive_care_age_00: int
  new_intensive_care_age_01: int
  new_intensive_care_age_02: int
  new_intensive_care_age_03: int
  new_intensive_care_age_04: int
  new_intensive_care_age_05: int
  new_intensive_care_age_06: int
  new_intensive_care_age_07: int
  new_intensive_care_age_08: int
  new_intensive_care_age_09: int
  total_intensive_care_age_00: int
  total_intensive_care_age_01: int
  total_intensive_care_age_02: int
  total_intensive_care_age_03: int
  total_intensive_care_age_04: int
  total_intensive_care_age_05: int
  total_intensive_care_age_06: int
  total_intensive_care_age_07: int
  total_intensive_care_age_08: int
  total_intensive_care_age_09: int
  current_intensive_care_age_00: int
  current_intensive_care_age_01: int
  current_intensive_care_age_02: int
  current_intensive_care_age_03: int
  current_intensive_care_age_04: int
  current_intensive_care_age_05: int
  current_intensive_care_age_06: int
  current_intensive_care_age_07: int
  current_intensive_care_age_08: int
  current_intensive_care_age_09: int
  new_ventilator_age_00: int
  new_ventilator_age_01: int
  new_ventilator_age_02: int
  new_ventilator_age_03: int
  new_ventilator_age_04: int
  new_ventilator_age_05: int
  new_ventilator_age_06: int
  new_ventilator_age_07: int
  new_ventilator_age_08: int
  new_ventilator_age_09: int
  total_ventilator_age_00: int
  total_ventilator_age_01: int
  total_ventilator_age_02: int
  total_ventilator_age_03: int
  total_ventilator_age_04: int
  total_ventilator_age_05: int
  total_ventilator_age_06: int
  total_ventilator_age_07: int
  total_ventilator_age_08: int
  total_ventilator_age_09: int
  current_ventilator_age_00: int
  current_ventilator_age_01: int
  current_ventilator_age_02: int
  current_ventilator_age_03: int
  current_ventilator_age_04: int
  current_ventilator_age_05: int
  current_ventilator_age_06: int
  current_ventilator_age_07: int
  current_ventilator_age_08: int
  current_ventilator_age_09: int
  age_bin_00: str
  age_bin_01: str
  age_bin_02: str
  age_bin_03: str
  age_bin_04: str
  age_bin_05: str
  age_bin_06: str
  age_bin_07: str
  age_bin_08: str
  age_bin_09: str

auxiliary:
  metadata: ./data/metadata.csv
  country_codes: ./data/country_codes.csv
  knowledge_graph: ./data/knowledge_graph.csv

sources:

  # Data sources for AR levels 2 + 3
  - name: pipelines.epidemiology.ar_authority.ArgentinaDataSource
    fetch:
      - url: "https://sisa.msal.gov.ar/datos/descargas/covid-19/files/Covid19Casos.csv"
    parse:
      encoding: UTF-16-LE
    test:
      # Skip because it's too slow
      skip: true
      metadata_query: "key.str.match('AR_.*')"

  # Data sources for BR_AC level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: AC
    test:
      metadata_query: "key.str.match('BR_AC_.+')"
      # Skip because it's too slow
      skip: true
    automation:
      job_group: brazil_federal

  # Data sources for BR_AL level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: AL
    test:
      metadata_query: "key.str.match('BR_AL_.+')"
      # Skip because it's too slow
      skip: true
    automation:
      job_group: brazil_federal

  # Data sources for BR_AM level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: AM
    test:
      metadata_query: "key.str.match('BR_AM_.+')"
      # Skip because it's too slow
      skip: true

  # Data sources for BR_AP level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: AP
    test:
      metadata_query: "key.str.match('BR_AP_.+')"
      # Skip because it's too slow
      skip: true
    automation:
      job_group: brazil_federal

  # Data sources for BR_BA level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: BA
    test:
      metadata_query: "key.str.match('BR_BA_.+')"
      # Skip because it's too slow
      skip: true
    automation:
      job_group: brazil_federal

  # Data sources for BR_CE level 3
  - name: pipelines.epidemiology.br_ce_authority.CearaDataSource
    fetch:
      - url: "http://download-integrasus.saude.ce.gov.br/download"
        opts:
          ext: zip
    test:
      # Skip non-working pipeline
      # TODO(owahltinez): replace with br_authority source
      skip: true
      metadata_query: "key.str.match('BR_CE.+')"

  # Data sources for BR_DF level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: DF
    test:
      metadata_query: "key.str.match('BR_DF_.+')"
      # Skip because it's too slow
      skip: true
    automation:
      job_group: brazil_federal

  # Data sources for BR_ES level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: ES
    test:
      metadata_query: "key.str.match('BR_ES_.+')"
      # Skip because it's too slow
      skip: true
    automation:
      job_group: brazil_federal

  # Data sources for BR_GO level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: GO
    test:
      metadata_query: "key.str.match('BR_GO_.+')"
      # Skip because it's too slow
      skip: true
    automation:
      job_group: brazil_federal

  # Data sources for BR_MA level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: MA
    test:
      metadata_query: "key.str.match('BR_MA_.+')"
      # Skip because it's too slow
      skip: true
    automation:
      job_group: brazil_federal

  # TODO(owahltinez): work around CSV parsing error
  # # Data sources for BR_MG level 3
  # - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
  #   fetch:
  #     - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
  #   parse:
  #       sep: ";"
  #       encoding: "ISO-8859-1"
  #       subregion1_code: MG
  #   test:
  #     metadata_query: "key.str.match('BR_MG_.+')"
  #     # Skip because it's too slow
  #     skip: true
  #   automation:
  #     job_group: brazil_federal

  # Data sources for BR_MS level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: MS
    test:
      metadata_query: "key.str.match('BR_MS_.+')"
      # Skip because it's too slow
      skip: true
    automation:
      job_group: brazil_federal

  # Data sources for BR_MT level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: MT
    test:
      metadata_query: "key.str.match('BR_MT_.+')"
      # Skip because it's too slow
      skip: true
    automation:
      job_group: brazil_federal

  # Data sources for BR_PA level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: PA
    test:
      metadata_query: "key.str.match('BR_PA_.+')"
      # Skip because it's too slow
      skip: true
    automation:
      job_group: brazil_federal

  # Data sources for BR_PB level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: PB
    test:
      metadata_query: "key.str.match('BR_PB_.+')"
      # Skip because it's too slow
      skip: true
    automation:
      job_group: brazil_federal

  # TODO(owahltinez): fix key mismatch for BR_PE_260545
  # Data sources for BR_PE level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: PE
    test:
      metadata_query: "key.str.match('BR_PE_.+')"
      # Skip because it's too slow
      skip: true
    automation:
      job_group: brazil_federal

  # Data sources for BR_PI level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: PI
    test:
      metadata_query: "key.str.match('BR_PI_.+')"
      # Skip because it's too slow
      skip: true
    automation:
      job_group: brazil_federal

  # TODO(owahltinez): work around CSV parsing error
  # # Data sources for BR_PR level 3
  # - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
  #   fetch:
  #     - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
  #   parse:
  #       sep: ";"
  #       encoding: "ISO-8859-1"
  #       subregion1_code: PR
  #   test:
  #     metadata_query: "key.str.match('BR_PR_.+')"
  #     # Skip because it's too slow
  #     skip: true
  #   automation:
  #     job_group: brazil_federal

  # Data sources for BR_RJ level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: RJ
    test:
      metadata_query: "key.str.match('BR_RJ_.+')"
      # Skip because it's too slow
      skip: true
    automation:
      job_group: brazil_federal

  # Data sources for BR_RJ level 3
  - name: pipelines.epidemiology.br_rj_authority.RioStratifiedDataSource
    fetch:
      - url: "https://pcrj.maps.arcgis.com/sharing/rest/content/items/754cc0698129404ba8bfb053cbdbd158/data"
        opts:
          ext: csv
    parse:
      sep: ";"
      encoding: "ISO-8859-1"
    test:
      metadata_query: "key == 'BR_RJ_GIG'"

  # Data sources for BR_RN level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: RN
    test:
      metadata_query: "key.str.match('BR_RN_.+')"
      # Skip because it's too slow
      skip: true
    automation:
      job_group: brazil_federal

  # Data sources for BR_RS level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: RS
    test:
      metadata_query: "key.str.match('BR_RS_.+')"
      # Skip because it's too slow
      skip: true
    automation:
      job_group: brazil_federal

  # Data sources for BR_SC level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: SC
    test:
      metadata_query: "key.str.match('BR_SC_.+')"
      # Skip because it's too slow
      skip: true
    automation:
      job_group: brazil_federal

  # Data sources for BR_SE level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: SE
    test:
      metadata_query: "key.str.match('BR_SE_.+')"
      # Skip because it's too slow
      skip: true
    automation:
      job_group: brazil_federal

  # Data sources for BR_SP level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: SP
    test:
      metadata_query: "key.str.match('BR_SP_.+')"
      # Skip because it's too slow
      skip: true
    automation:
      job_group: brazil_federal

  # Data sources for BR_TO level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: TO
    test:
      metadata_query: "key.str.match('BR_TO_.+')"
      # Skip because it's too slow
      skip: true
    automation:
      job_group: brazil_federal

  # Data sources for CZ levels 1 + 2 + 3
  - name: pipelines.epidemiology.cz_authority.CzechRepublicAgeSexDataSource
    fetch:
      - url: "https://onemocneni-aktualne.mzcr.cz/api/v2/covid-19/osoby.csv"
    parse:
      column_name: 'new_confirmed'
    test:
      metadata_query: "key.str.match('CZ.*')"

  - name: pipelines.epidemiology.cz_authority.CzechRepublicAgeSexDataSource
    fetch:
      - url: "https://onemocneni-aktualne.mzcr.cz/api/v2/covid-19/umrti.csv"
    parse:
      column_name: 'new_deceased'
    test:
      metadata_query: "key.str.match('CZ.*')"

  - name: pipelines.epidemiology.cz_authority.CzechRepublicAgeSexDataSource
    fetch:
      - url: "https://onemocneni-aktualne.mzcr.cz/api/v2/covid-19/vyleceni.csv"
    parse:
      column_name: 'new_recovered'
    test:
      metadata_query: "key.str.match('CZ.*')"

  # Data sources for FI level 1
  - name: pipelines.epidemiology.fi_authority.FinlandArcGisDataSource
    fetch:
      - url: https://services7.arcgis.com/nuPvVz1HGGfa0Eh7/arcgis/rest/services/korona_tapauksia_jakauma/FeatureServer/0/query?f=json&where=1%3D1&outFields=OBJECTID,alue,date,tapauksia,miehia,naisia,Ika_0_9,ika_10_19,ika_20_29,ika_30_39,ika_40_49,ika_50_59,ika_60_69,ika_70_79,ika_80_,koodi&returnGeometry=false
        opts:
          ext: json
    query: "date > '2020-02-01'"
    test:
      metadata_query: "key == 'FI'"

  # TODO(owahltinez): Parse stratified information from FR data source

  # Data sources for MX levels 1, 2 and 3
  - name: pipelines.epidemiology.mx_authority.MexicoDataSource
    fetch:
      - url: "http://187.191.75.115/gobmx/salud/datos_abiertos/datos_abiertos_covid19.zip"
    parse:
      encoding: "ISO-8859-1"
    test:
      # Skip this data source because it's too slow
      skip: true
      metadata_query: "key.str.match('MX_.+')"

  # Data sources for PE levels 2 + 3
  - name: pipelines.epidemiology.pe_authority.PeruDataSource
    fetch:
      - name: confirmed
        url: "https://cloud.minsa.gob.pe/s/Y8w3wHsEdYQSZRp/download"
        opts:
          ext: csv
      - name: deceased
        url: "https://cloud.minsa.gob.pe/s/Md37cjXmjT9qYSa/download"
        opts:
          ext: csv
    parse:
      encoding: "ISO-8859-1"
    test:
      metadata_query: "key.str.match('PE_.+')"

  # Data sources for PH levels 2 + 3
  # To update this data source:
  # 1. Go to http://bit.ly/DataDropArchives
  # 2. Find the folder with the latest date available
  # 3. Get the sharing URL for the "04 Case Information.csv" file
  # 4. Use https://sites.google.com/site/gdocs2direct/ to get a direct link
  # 5. Replace the URL below with that link in epidemiology, hospitalizations, by-age and by-sex
  # and replace the link with
  - name: pipelines.epidemiology.ph_authority.PhilippinesDataSource
    fetch:
      - url: "https://drive.google.com/uc?export=download&id=1nTq39yB2w4ZpL2qmbkSCByv_nqaEL7Cd"
        opts:
          ext: csv
    test:
      metadata_query: "key.str.match('PH.*')"

  # Data sources for US_DC level 2
  - name: pipelines.epidemiology.us_dc_authority.DistrictColumbiaDataSource
    fetch:
      - url: "https://coronavirus.dc.gov/page/coronavirus-data"
        opts:
          ext: xlsx
    parse:
      sheet_name: "Lives Lost by Age"
    test:
      # Skip because it's too flakey
      skip: true
      metadata_query: "key == 'US_DC'"

  # Data sources for US_DE level 2
  - name: pipelines.epidemiology.us_de_authority.DelawareDataSource
    fetch:
      - url: "https://myhealthycommunity.dhss.delaware.gov/locations/state/download_covid_19_data"
        opts:
          ext: csv
          spoof_browser: false
          # Only download data from source once (in epidemiology pipeline)
          skip_existing: true
    test:
      metadata_query: "key == 'US_DE'"
      # Skip because endpoint fails frequently
      skip: true

  # Data sources US_FL levels 2 + 3
  - name: pipelines.epidemiology.us_fl_authority.FloridaDataSource
    # No URL is provided because an API is used instead
    test:
      metadata_query: "key.str.match('US_FL.*')"
      # Skip Florida because download takes a long time
      skip: true

  - name: pipelines.epidemiology.us_in_authority.IndianaDataSource
    fetch:
      - url: "https://hub.mph.in.gov/dataset/6b57a4f2-b754-4f79-a46b-cff93e37d851/resource/46b310b9-2f29-4a51-90dc-3886d9cf4ac1/download/covid_report.xlsx"
        opts:
          ext: xlsx
          # Only download data from source once (in epidemiology pipeline)
          skip_existing: true
    test:
      metadata_query: "key.str.match('US_IN.*')"

  # Data sources for ZA level 1
  - name: pipelines.epidemiology.za_dsfsi.Covid19ZaTimelineDeathsDataSource
    fetch:
      - url: "https://raw.github.com/dsfsi/covid19za/master/data/covid19za_timeline_death_statistics.csv"
    test:
      metadata_query: "key == 'ZA'"
