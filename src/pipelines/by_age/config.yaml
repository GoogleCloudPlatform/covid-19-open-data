# Copyright 2020 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Age stratified pipeline configuration

schema:
  date: str
  key: str
  new_confirmed_age_00: int
  new_confirmed_age_01: int
  new_confirmed_age_02: int
  new_confirmed_age_03: int
  new_confirmed_age_04: int
  new_confirmed_age_05: int
  new_confirmed_age_06: int
  new_confirmed_age_07: int
  new_confirmed_age_08: int
  new_confirmed_age_09: int
  total_confirmed_age_00: int
  total_confirmed_age_01: int
  total_confirmed_age_02: int
  total_confirmed_age_03: int
  total_confirmed_age_04: int
  total_confirmed_age_05: int
  total_confirmed_age_06: int
  total_confirmed_age_07: int
  total_confirmed_age_08: int
  total_confirmed_age_09: int
  new_deceased_age_00: int
  new_deceased_age_01: int
  new_deceased_age_02: int
  new_deceased_age_03: int
  new_deceased_age_04: int
  new_deceased_age_05: int
  new_deceased_age_06: int
  new_deceased_age_07: int
  new_deceased_age_08: int
  new_deceased_age_09: int
  total_deceased_age_00: int
  total_deceased_age_01: int
  total_deceased_age_02: int
  total_deceased_age_03: int
  total_deceased_age_04: int
  total_deceased_age_05: int
  total_deceased_age_06: int
  total_deceased_age_07: int
  total_deceased_age_08: int
  total_deceased_age_09: int
  new_recovered_age_00: int
  new_recovered_age_01: int
  new_recovered_age_02: int
  new_recovered_age_03: int
  new_recovered_age_04: int
  new_recovered_age_05: int
  new_recovered_age_06: int
  new_recovered_age_07: int
  new_recovered_age_08: int
  new_recovered_age_09: int
  total_recovered_age_00: int
  total_recovered_age_01: int
  total_recovered_age_02: int
  total_recovered_age_03: int
  total_recovered_age_04: int
  total_recovered_age_05: int
  total_recovered_age_06: int
  total_recovered_age_07: int
  total_recovered_age_08: int
  total_recovered_age_09: int
  new_tested_age_00: int
  new_tested_age_01: int
  new_tested_age_02: int
  new_tested_age_03: int
  new_tested_age_04: int
  new_tested_age_05: int
  new_tested_age_06: int
  new_tested_age_07: int
  new_tested_age_08: int
  new_tested_age_09: int
  total_tested_age_00: int
  total_tested_age_01: int
  total_tested_age_02: int
  total_tested_age_03: int
  total_tested_age_04: int
  total_tested_age_05: int
  total_tested_age_06: int
  total_tested_age_07: int
  total_tested_age_08: int
  total_tested_age_09: int
  new_hospitalized_age_00: int
  new_hospitalized_age_01: int
  new_hospitalized_age_02: int
  new_hospitalized_age_03: int
  new_hospitalized_age_04: int
  new_hospitalized_age_05: int
  new_hospitalized_age_06: int
  new_hospitalized_age_07: int
  new_hospitalized_age_08: int
  new_hospitalized_age_09: int
  total_hospitalized_age_00: int
  total_hospitalized_age_01: int
  total_hospitalized_age_02: int
  total_hospitalized_age_03: int
  total_hospitalized_age_04: int
  total_hospitalized_age_05: int
  total_hospitalized_age_06: int
  total_hospitalized_age_07: int
  total_hospitalized_age_08: int
  total_hospitalized_age_09: int
  current_hospitalized_age_00: int
  current_hospitalized_age_01: int
  current_hospitalized_age_02: int
  current_hospitalized_age_03: int
  current_hospitalized_age_04: int
  current_hospitalized_age_05: int
  current_hospitalized_age_06: int
  current_hospitalized_age_07: int
  current_hospitalized_age_08: int
  current_hospitalized_age_09: int
  new_intensive_care_age_00: int
  new_intensive_care_age_01: int
  new_intensive_care_age_02: int
  new_intensive_care_age_03: int
  new_intensive_care_age_04: int
  new_intensive_care_age_05: int
  new_intensive_care_age_06: int
  new_intensive_care_age_07: int
  new_intensive_care_age_08: int
  new_intensive_care_age_09: int
  total_intensive_care_age_00: int
  total_intensive_care_age_01: int
  total_intensive_care_age_02: int
  total_intensive_care_age_03: int
  total_intensive_care_age_04: int
  total_intensive_care_age_05: int
  total_intensive_care_age_06: int
  total_intensive_care_age_07: int
  total_intensive_care_age_08: int
  total_intensive_care_age_09: int
  current_intensive_care_age_00: int
  current_intensive_care_age_01: int
  current_intensive_care_age_02: int
  current_intensive_care_age_03: int
  current_intensive_care_age_04: int
  current_intensive_care_age_05: int
  current_intensive_care_age_06: int
  current_intensive_care_age_07: int
  current_intensive_care_age_08: int
  current_intensive_care_age_09: int
  new_ventilator_age_00: int
  new_ventilator_age_01: int
  new_ventilator_age_02: int
  new_ventilator_age_03: int
  new_ventilator_age_04: int
  new_ventilator_age_05: int
  new_ventilator_age_06: int
  new_ventilator_age_07: int
  new_ventilator_age_08: int
  new_ventilator_age_09: int
  total_ventilator_age_00: int
  total_ventilator_age_01: int
  total_ventilator_age_02: int
  total_ventilator_age_03: int
  total_ventilator_age_04: int
  total_ventilator_age_05: int
  total_ventilator_age_06: int
  total_ventilator_age_07: int
  total_ventilator_age_08: int
  total_ventilator_age_09: int
  current_ventilator_age_00: int
  current_ventilator_age_01: int
  current_ventilator_age_02: int
  current_ventilator_age_03: int
  current_ventilator_age_04: int
  current_ventilator_age_05: int
  current_ventilator_age_06: int
  current_ventilator_age_07: int
  current_ventilator_age_08: int
  current_ventilator_age_09: int
  age_bin_00: str
  age_bin_01: str
  age_bin_02: str
  age_bin_03: str
  age_bin_04: str
  age_bin_05: str
  age_bin_06: str
  age_bin_07: str
  age_bin_08: str
  age_bin_09: str

auxiliary:
  metadata: ./data/metadata.csv
  localities: ./data/localities.csv
  country_codes: ./data/country_codes.csv
  knowledge_graph: ./data/knowledge_graph.csv

sources:

  # Data sources for AR levels 2 + 3
  - name: pipelines.epidemiology.ar_authority.ArgentinaDataSource
    fetch:
      - url: "https://sisa.msal.gov.ar/datos/descargas/covid-19/files/Covid19Casos.csv"
    test:
      # Skip because it's too slow
      skip: true
      location_key_match: 'AR_.*'
    automation:
      job_group: all
      deferred: true

  # Data sources for BR_AC level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: AC
        # This data source does not report zero values, so we fill them in
        fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      location_key_match: 'BR_AC_.+'
      # Skip because it's too slow
      skip: true
    automation:
      job_group: all
      deferred: true

  # Data sources for BR_AL level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: AL
        # This data source does not report zero values, so we fill them in
        fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      location_key_match: 'BR_AL_.+'
      # Skip because it's too slow
      skip: true
    automation:
      job_group: all
      deferred: true

  # Data sources for BR_AM level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: AM
        # This data source does not report zero values, so we fill them in
        fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      location_key_match: 'BR_AM_.+'
      # Skip because it's too slow
      skip: true
    automation:
      job_group: all
      deferred: true

  # Data sources for BR_AP level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: AP
        # This data source does not report zero values, so we fill them in
        fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      location_key_match: 'BR_AP_.+'
      # Skip because it's too slow
      skip: true
    automation:
      job_group: all
      deferred: true

  # Data sources for BR_BA level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: BA
        # This data source does not report zero values, so we fill them in
        fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      location_key_match: 'BR_BA_.+'
      # Skip because it's too slow
      skip: true
    automation:
      job_group: all
      deferred: true

  # Data sources for BR_CE level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: CE
        # This data source does not report zero values, so we fill them in
        fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      location_key_match: 'BR_CE_.+'
      # Skip because it's too slow
      skip: true
    automation:
      job_group: all
      deferred: true

  # Data sources for BR_DF level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: DF
        # This data source does not report zero values, so we fill them in
        fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      location_key_match: 'BR_DF_.+'
      # Skip because it's too slow
      skip: true
    automation:
      job_group: all
      deferred: true

  # Data sources for BR_ES level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: ES
        # This data source does not report zero values, so we fill them in
        fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      location_key_match: 'BR_ES_.+'
      # Skip because it's too slow
      skip: true
    automation:
      job_group: all
      deferred: true

  # Data sources for BR_GO level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: GO
        # This data source does not report zero values, so we fill them in
        fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      location_key_match: 'BR_GO_.+'
      # Skip because it's too slow
      skip: true
    automation:
      job_group: all
      deferred: true

  # Data sources for BR_MA level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: MA
        # This data source does not report zero values, so we fill them in
        fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      location_key_match: 'BR_MA_.+'
      # Skip because it's too slow
      skip: true
    automation:
      job_group: all
      deferred: true

  # Data sources for BR_MG level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: MG
        # This data source does not report zero values, so we fill them in
        fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      location_key_match: 'BR_MG_.+'
      # Skip because it's too slow
      skip: true
    automation:
      job_group: all
      deferred: true

  # Data sources for BR_MS level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: MS
        # This data source does not report zero values, so we fill them in
        fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      location_key_match: 'BR_MS_.+'
      # Skip because it's too slow
      skip: true
    automation:
      job_group: all
      deferred: true

  # Data sources for BR_MT level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: MT
        # This data source does not report zero values, so we fill them in
        fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      location_key_match: 'BR_MT_.+'
      # Skip because it's too slow
      skip: true
    automation:
      job_group: all
      deferred: true

  # Data sources for BR_PA level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: PA
        # This data source does not report zero values, so we fill them in
        fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      location_key_match: 'BR_PA_.+'
      # Skip because it's too slow
      skip: true
    automation:
      job_group: all
      deferred: true

  # Data sources for BR_PB level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: PB
        # This data source does not report zero values, so we fill them in
        fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      location_key_match: 'BR_PB_.+'
      # Skip because it's too slow
      skip: true
    automation:
      job_group: all
      deferred: true

  # TODO(owahltinez): fix key mismatch for BR_PE_260545
  # Data sources for BR_PE level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: PE
        # This data source does not report zero values, so we fill them in
        fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      location_key_match: 'BR_PE_.+'
      # Skip because it's too slow
      skip: true
    automation:
      job_group: all
      deferred: true

  # Data sources for BR_PI level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: PI
        # This data source does not report zero values, so we fill them in
        fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      location_key_match: 'BR_PI_.+'
      # Skip because it's too slow
      skip: true
    automation:
      job_group: all
      deferred: true

  # Data sources for BR_PR level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: PR
        # This data source does not report zero values, so we fill them in
        fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      location_key_match: 'BR_PR_.+'
      # Skip because it's too slow
      skip: true
    automation:
      job_group: all
      deferred: true

  # Data sources for BR_RJ level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: RJ
        # This data source does not report zero values, so we fill them in
        fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      location_key_match: 'BR_RJ_.+'
      # Skip because it's too slow
      skip: true
    automation:
      job_group: all
      deferred: true

  # Data sources for BR_RJ level 3
  - name: pipelines.epidemiology.br_rj_authority.RioStratifiedDataSource
    fetch:
      - url: "https://pcrj.maps.arcgis.com/sharing/rest/content/items/754cc0698129404ba8bfb053cbdbd158/data"
        opts:
          ext: csv
    parse:
      sep: ";"
      encoding: "ISO-8859-1"
    test:
      location_key_match: '^BR_RJ_GIG$'
      # Skip because it's very flakey
      skip: true
    automation:
      job_group: all
      deferred: true

  # Data sources for BR_RN level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: RN
        # This data source does not report zero values, so we fill them in
        fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      location_key_match: 'BR_RN_.+'
      # Skip because it's too slow
      skip: true
    automation:
      job_group: all
      deferred: true

  # Data sources for BR_RS level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: RS
        # This data source does not report zero values, so we fill them in
        fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      location_key_match: 'BR_RS_.+'
      # Skip because it's too slow
      skip: true
    automation:
      job_group: all
      deferred: true

  # Data sources for BR_SC level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: SC
        # This data source does not report zero values, so we fill them in
        fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      location_key_match: 'BR_SC_.+'
      # Skip because it's too slow
      skip: true
    automation:
      job_group: all
      deferred: true

  # Data sources for BR_SE level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: SE
        # This data source does not report zero values, so we fill them in
        fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      location_key_match: 'BR_SE_.+'
      # Skip because it's too slow
      skip: true
    automation:
      job_group: all
      deferred: true

  # Data sources for BR_SP level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: SP
        # This data source does not report zero values, so we fill them in
        fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      location_key_match: 'BR_SP_.+'
      # Skip because it's too slow
      skip: true
    automation:
      job_group: all
      deferred: true

  # Data sources for BR_TO level 3
  - name: pipelines.epidemiology.br_authority.BrazilStratifiedDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
        sep: ";"
        encoding: "ISO-8859-1"
        subregion1_code: TO
        # This data source does not report zero values, so we fill them in
        fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      location_key_match: 'BR_TO_.+'
      # Skip because it's too slow
      skip: true
    automation:
      job_group: all
      deferred: true

  # Data sources for CO levels 1 + 2 + 3
  - name: pipelines.epidemiology.co_authority.ColombiaDataSource
    fetch:
      - url: "https://www.datos.gov.co/api/views/gt2j-8ykr/rows.csv"
    test:
      location_key_match: 'CO.*'
    automation:
      job_group: all
      deferred: true

  # Data sources for CZ levels 1 + 2 + 3
  - name: pipelines.epidemiology.cz_authority.CzechRepublicAgeSexDataSource
    fetch:
      - url: "https://onemocneni-aktualne.mzcr.cz/api/v2/covid-19/osoby.csv"
    parse:
      column_name: 'new_confirmed'
    test:
      location_key_match: 'CZ.*'
    automation:
      job_group: all
      deferred: true

  - name: pipelines.epidemiology.cz_authority.CzechRepublicAgeSexDataSource
    fetch:
      - url: "https://onemocneni-aktualne.mzcr.cz/api/v2/covid-19/umrti.csv"
    parse:
      column_name: 'new_deceased'
    test:
      location_key_match: 'CZ.*'
    automation:
      job_group: all
      deferred: true

  - name: pipelines.epidemiology.cz_authority.CzechRepublicAgeSexDataSource
    fetch:
      - url: "https://onemocneni-aktualne.mzcr.cz/api/v2/covid-19/vyleceni.csv"
    parse:
      column_name: 'new_recovered'
    test:
      location_key_match: 'CZ.*'
    automation:
      job_group: all
      deferred: true

  # Data sources for ES_CT levels 2
  - name: pipelines.epidemiology.es_ct_authority.CataloniaHealthDeptDataSource
    fetch:
      - url: "https://analisi.transparenciacatalunya.cat/api/views/qwj8-xpvk/rows.csv"
    parse:
      dtype: str
    test:
      location_key_match: '^ES_CT$'
    automation:
      job_group: all
      deferred: true

  # Data sources for FI level 1
  - name: pipelines.epidemiology.fi_authority.FinlandArcGisDataSource
    fetch:
      - url: https://services7.arcgis.com/nuPvVz1HGGfa0Eh7/arcgis/rest/services/korona_tapauksia_jakauma/FeatureServer/0/query?f=json&where=1%3D1&outFields=OBJECTID,alue,date,tapauksia,miehia,naisia,Ika_0_9,ika_10_19,ika_20_29,ika_30_39,ika_40_49,ika_50_59,ika_60_69,ika_70_79,ika_80_,koodi&returnGeometry=false
        opts:
          ext: json
    query: "date > '2020-02-01'"
    test:
      location_key_match: '^FI$'
    automation:
      job_group: all
      deferred: true

  # TODO(owahltinez): Parse stratified information from FR data source

  # Data sources for MX levels 1, 2 and 3
  - name: pipelines.epidemiology.mx_authority.MexicoDataSource
    fetch:
      - url: "http://datosabiertos.salud.gob.mx/gobmx/salud/datos_abiertos/datos_abiertos_covid19.zip"
    parse:
      encoding: "ISO-8859-1"
      # This data source does not report zero values, so we fill them in
      fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      # Skip this data source because it's too slow
      skip: true
      location_key_match: 'MX_.+'
    automation:
      job_group: all
      deferred: true

  # Data sources for PE levels 2 + 3
  - name: pipelines.epidemiology.pe_authority.PeruDataSource
    fetch:
      - name: confirmed
        url: "https://cloud.minsa.gob.pe/s/Y8w3wHsEdYQSZRp/download"
        opts:
          ext: csv
      - name: deceased
        url: "https://cloud.minsa.gob.pe/s/Md37cjXmjT9qYSa/download"
        opts:
          ext: csv
    parse:
      encoding: "ISO-8859-1"
      sep: ";"
    test:
      location_key_match: 'PE_.+'
      # Skip because this is a flakey data source
      skip: true
    automation:
      job_group: all
      deferred: true

  # Data sources for PH levels 2 + 3
  # To update this data source:
  # 1. Go to http://bit.ly/DataDropArchives
  # 2. Find the folder with the latest date available
  # 3. Get the sharing URL for the "04 Case Information.csv" file
  # 4. Use https://sites.google.com/site/gdocs2direct/ to get a direct link
  # 5. Replace the URL below with that link in epidemiology, hospitalizations, by-age and by-sex
  # and replace the link with
  - name: pipelines.epidemiology.ph_authority.PhilippinesDataSource
    fetch:
      - url: "https://drive.google.com/uc?id=1VjcwVMZ-SflpfMnmNKjT4NhKfSmFEJMD&export=csv"
        opts:
          ext: csv
    test:
      location_key_match: 'PH.*'
    automation:
      job_group: all
      deferred: true

  # Data sources for RO level 1
  - name: pipelines.epidemiology.ro_authority.RomaniaDataSource
    fetch:
      - url: "https://d35p9e4fm9h3wo.cloudfront.net/latestData.json"
    parse:
      skip_county: true
    test:
      location_key_match: '^RO$'
    automation:
      job_group: all
      deferred: true

  # Data sources for US level 2
  - name: pipelines.epidemiology.us_imperial.ImperialDataSource
    fetch:
      - url: "https://raw.githubusercontent.com/ImperialCollegeLondon/US-covid19-agespecific-mortality-data/master/data/processed/latest/DeathsByAge_US.csv"
    test:
      location_key_match: '^US_\w\w(_NYC)?$'
    automation:
      job_group: all
      deferred: true

  # Data sources for US_DC level 2
  - name: pipelines.epidemiology.us_dc_authority.DistrictColumbiaDataSource
    fetch:
      - url: "https://coronavirus.dc.gov/page/coronavirus-data"
        opts:
          ext: xlsx
    parse:
      sheet_name: "Lives Lost by Age"
    test:
      # Skip because it's too flakey
      skip: true
      location_key_match: '^US_DC$'
    automation:
      job_group: all
      deferred: true

  # Data sources for US_DE level 2
  - name: pipelines.epidemiology.us_de_authority.DelawareDataSource
    fetch:
      - url: "https://myhealthycommunity.dhss.delaware.gov/locations/state/download_covid_19_data"
        opts:
          ext: csv
          spoof_browser: false
    test:
      location_key_match: '^US_DE$'
      # Skip because endpoint fails frequently
      skip: true
    automation:
      job_group: all
      deferred: true

  # Data sources US_FL levels 2 + 3
  - name: pipelines.epidemiology.us_fl_authority.FloridaDataSource
    # No URL is provided because an API is used instead
    test:
      location_key_match: 'US_FL.*'
      # Skip Florida because download takes a long time
      skip: true
    automation:
      job_group: all
      deferred: true

  # Data sources for US_GA levels 2 + 3
  - name: pipelines.by_age.us_ga_authority.GeorgiaStratifiedDataSource
    # No URL is given because it uses the cache
    fetch:
      - cache_key: US_GA_stratified
    parse:
      file_name: demographics_by_age_group.csv
      date_start: "2020-10-01"
    test:
      location_key_match: 'US_GA_.*'
    automation:
      job_group: all
      deferred: true

  # Data sources for US_IN level 3
  - name: pipelines.epidemiology.us_in_authority.IndianaDataSource
    fetch:
      - url: "https://hub.mph.in.gov/dataset/6b57a4f2-b754-4f79-a46b-cff93e37d851/resource/46b310b9-2f29-4a51-90dc-3886d9cf4ac1/download/covid_report.xlsx"
        opts:
          ext: xlsx
    # Only aggregate age/sex pipelines to state level because the data does not add up to the total
    # number of cases. This is because small case counts are excluded for privacy reasons.
    aggregate:
      subregion2: ['new_confirmed_age_*']
    parse:
      # This data source does not report zero values, so we fill them in
      fill_with_zeroes: ['new_confirmed_age_*']
    test:
      location_key_match: 'US_IN.*'
    automation:
      job_group: all
      deferred: true

  # Data sources for US_MA level 3
  - name: pipelines.epidemiology.us_ma_authority.MassachusettsByAgeDataSource
    fetch:
      - name: by-age
        # August 11th was the last day US_MA reported cases broken down by age/sex
        url: "https://www.mass.gov/doc/covid-19-raw-data-august-11-2020/download"
        opts:
          ext: zip
    parse:
      file_name: Age.csv
    test:
      location_key_match: '^US_MA$'
    automation:
      job_group: all
      deferred: true
