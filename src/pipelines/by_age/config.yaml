# Copyright 2020 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Age stratified pipeline configuration

schema:
  date: str
  key: str
  new_confirmed_age_00: int
  new_confirmed_age_01: int
  new_confirmed_age_02: int
  new_confirmed_age_03: int
  new_confirmed_age_04: int
  new_confirmed_age_05: int
  new_confirmed_age_06: int
  new_confirmed_age_07: int
  new_confirmed_age_08: int
  new_confirmed_age_09: int
  total_confirmed_age_00: int
  total_confirmed_age_01: int
  total_confirmed_age_02: int
  total_confirmed_age_03: int
  total_confirmed_age_04: int
  total_confirmed_age_05: int
  total_confirmed_age_06: int
  total_confirmed_age_07: int
  total_confirmed_age_08: int
  total_confirmed_age_09: int
  new_deceased_age_00: int
  new_deceased_age_01: int
  new_deceased_age_02: int
  new_deceased_age_03: int
  new_deceased_age_04: int
  new_deceased_age_05: int
  new_deceased_age_06: int
  new_deceased_age_07: int
  new_deceased_age_08: int
  new_deceased_age_09: int
  total_deceased_age_00: int
  total_deceased_age_01: int
  total_deceased_age_02: int
  total_deceased_age_03: int
  total_deceased_age_04: int
  total_deceased_age_05: int
  total_deceased_age_06: int
  total_deceased_age_07: int
  total_deceased_age_08: int
  total_deceased_age_09: int
  new_recovered_age_00: int
  new_recovered_age_01: int
  new_recovered_age_02: int
  new_recovered_age_03: int
  new_recovered_age_04: int
  new_recovered_age_05: int
  new_recovered_age_06: int
  new_recovered_age_07: int
  new_recovered_age_08: int
  new_recovered_age_09: int
  total_recovered_age_00: int
  total_recovered_age_01: int
  total_recovered_age_02: int
  total_recovered_age_03: int
  total_recovered_age_04: int
  total_recovered_age_05: int
  total_recovered_age_06: int
  total_recovered_age_07: int
  total_recovered_age_08: int
  total_recovered_age_09: int
  new_tested_age_00: int
  new_tested_age_01: int
  new_tested_age_02: int
  new_tested_age_03: int
  new_tested_age_04: int
  new_tested_age_05: int
  new_tested_age_06: int
  new_tested_age_07: int
  new_tested_age_08: int
  new_tested_age_09: int
  total_tested_age_00: int
  total_tested_age_01: int
  total_tested_age_02: int
  total_tested_age_03: int
  total_tested_age_04: int
  total_tested_age_05: int
  total_tested_age_06: int
  total_tested_age_07: int
  total_tested_age_08: int
  total_tested_age_09: int
  new_hospitalized_age_00: int
  new_hospitalized_age_01: int
  new_hospitalized_age_02: int
  new_hospitalized_age_03: int
  new_hospitalized_age_04: int
  new_hospitalized_age_05: int
  new_hospitalized_age_06: int
  new_hospitalized_age_07: int
  new_hospitalized_age_08: int
  new_hospitalized_age_09: int
  total_hospitalized_age_00: int
  total_hospitalized_age_01: int
  total_hospitalized_age_02: int
  total_hospitalized_age_03: int
  total_hospitalized_age_04: int
  total_hospitalized_age_05: int
  total_hospitalized_age_06: int
  total_hospitalized_age_07: int
  total_hospitalized_age_08: int
  total_hospitalized_age_09: int
  new_intensive_care_age_00: int
  new_intensive_care_age_01: int
  new_intensive_care_age_02: int
  new_intensive_care_age_03: int
  new_intensive_care_age_04: int
  new_intensive_care_age_05: int
  new_intensive_care_age_06: int
  new_intensive_care_age_07: int
  new_intensive_care_age_08: int
  new_intensive_care_age_09: int
  total_intensive_care_age_00: int
  total_intensive_care_age_01: int
  total_intensive_care_age_02: int
  total_intensive_care_age_03: int
  total_intensive_care_age_04: int
  total_intensive_care_age_05: int
  total_intensive_care_age_06: int
  total_intensive_care_age_07: int
  total_intensive_care_age_08: int
  total_intensive_care_age_09: int
  new_ventilator_age_00: int
  new_ventilator_age_01: int
  new_ventilator_age_02: int
  new_ventilator_age_03: int
  new_ventilator_age_04: int
  new_ventilator_age_05: int
  new_ventilator_age_06: int
  new_ventilator_age_07: int
  new_ventilator_age_08: int
  new_ventilator_age_09: int
  total_ventilator_age_00: int
  total_ventilator_age_01: int
  total_ventilator_age_02: int
  total_ventilator_age_03: int
  total_ventilator_age_04: int
  total_ventilator_age_05: int
  total_ventilator_age_06: int
  total_ventilator_age_07: int
  total_ventilator_age_08: int
  total_ventilator_age_09: int
  age_bin_00: str
  age_bin_01: str
  age_bin_02: str
  age_bin_03: str
  age_bin_04: str
  age_bin_05: str
  age_bin_06: str
  age_bin_07: str
  age_bin_08: str
  age_bin_09: str

auxiliary:
  metadata: ./data/metadata.csv
  localities: ./data/localities.csv
  country_codes: ./data/country_codes.csv
  knowledge_graph: ./data/knowledge_graph.csv

sources:

  # Data sources for AR levels 2 + 3
  - name: pipelines.epidemiology.ar_authority.ArgentinaDataSource
    fetch:
      - url: "https://sisa.msal.gov.ar/datos/descargas/covid-19/files/Covid19Casos.csv"
    test:
      # Skip because it's too slow
      skip: true
      location_key_match: 'AR_.*'
    automation:
      job_group: all
      deferred: true

  # Data sources for BR levels 1 + 2 + 3
  - name: pipelines.epidemiology.br_authority.BrazilOpenDataPortalDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-{0}.csv"
    parse:
      sep: ";"
      encoding: "ISO-8859-1"
      # This data source does not report zero values, so we fill them in
      fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      location_key_match: 'BR.*'
      # Skip because it's too slow
      skip: true
    automation:
      job_group: all
      deferred: true

  - name: pipelines.epidemiology.br_authority.BrazilSRAGDataSource
    fetch:
      - url: "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/SRAG/2020/INFLUD-{date}.csv"
        opts:
          date_format: '%d-%m-%Y'
    parse:
      sep: ";"
      encoding: "ISO-8859-1"
      # This data source does not report zero values, so we fill them in
      fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      location_key_match: 'BR.*'
      # Skip because it's too slow
      skip: true
    automation:
      job_group: all
      deferred: true

  # Data sources for BR_RJ level 3
  - name: pipelines.epidemiology.br_rj_authority.RioStratifiedDataSource
    fetch:
      - url: "https://pcrj.maps.arcgis.com/sharing/rest/content/items/754cc0698129404ba8bfb053cbdbd158/data"
        opts:
          ext: csv
    parse:
      sep: ";"
      encoding: "ISO-8859-1"
    test:
      location_key_match: '^BR_RJ_GIG$'
      # Skip because it's very flakey
      skip: true
    automation:
      job_group: all
      deferred: true

  # Data sources for CO levels 1 + 2 + 3
  - name: pipelines.epidemiology.co_authority.ColombiaDataSource
    fetch:
      - url: "https://www.datos.gov.co/api/views/gt2j-8ykr/rows.csv"
    test:
      location_key_match: 'CO.*'
    automation:
      job_group: all
      deferred: true

  # Data sources for CZ levels 1 + 2 + 3
  - name: pipelines.epidemiology.cz_authority.CzechRepublicAgeSexDataSource
    fetch:
      - url: "https://onemocneni-aktualne.mzcr.cz/api/v2/covid-19/osoby.csv"
    parse:
      column_name: 'new_confirmed'
      # This data source contains case line data, so any missing information means zero
      fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      location_key_match: 'CZ.*'
    automation:
      job_group: all
      deferred: true

  - name: pipelines.epidemiology.cz_authority.CzechRepublicAgeSexDataSource
    fetch:
      - url: "https://onemocneni-aktualne.mzcr.cz/api/v2/covid-19/umrti.csv"
    parse:
      column_name: 'new_deceased'
      # This data source contains case line data, so any missing information means zero
      fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      location_key_match: 'CZ.*'
    automation:
      job_group: all
      deferred: true

  - name: pipelines.epidemiology.cz_authority.CzechRepublicAgeSexDataSource
    fetch:
      - url: "https://onemocneni-aktualne.mzcr.cz/api/v2/covid-19/vyleceni.csv"
    parse:
      column_name: 'new_recovered'
      # This data source contains case line data, so any missing information means zero
      fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      location_key_match: 'CZ.*'
    automation:
      job_group: all
      deferred: true

  # Data sources for DE levels 0 + 1 + 2
  - name: pipelines.epidemiology.de_authority.GermanyDataSource
    fetch:
      - url: "https://opendata.arcgis.com/datasets/dd4580c810204019a7b8eb3e0b329dd6_0.csv"
    parse:
      # This data source contains case line data, so any missing information means zero
      fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      location_key_match:
        - '^DE$'
        - '^DE_[^_]+$'
        - '^DE_[^_]+_[^_]+$'
    automation:
      job_group: all
      deferred: true

  # Data sources for EE levels 0 + 1
  - name: pipelines.epidemiology.ee_authority.EstoniaDataSource
    fetch:
      - url: "https://opendata.digilugu.ee/opendata_covid19_test_results.csv"
    parse:
      dtype: str
      # This data source does not report zero values, so we fill them in
      fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      location_key_match:
        - '^EE+$'
        - '^EE_[^_]+$'
    automation:
      job_group: all
      deferred: true

  # Data sources for ES levels 0 + 1
  - name: pipelines.epidemiology.es_authority.ISCIIIStratifiedDataSource
    fetch:
      - url: "https://cnecovid.isciii.es/covid19/resources/casos_hosp_uci_def_sexo_edad_provres.csv"
    test:
      location_key_match:
        - '^ES$'
        - '^ES_[^_]+$'
    automation:
      job_group: all
      deferred: true

  # Data sources for ES_CT levels 2
  - name: pipelines.epidemiology.es_ct_authority.CataloniaHealthDeptDataSource
    fetch:
      - url: "https://analisi.transparenciacatalunya.cat/api/views/qwj8-xpvk/rows.csv"
    parse:
      dtype: str
    test:
      location_key_match: '^ES_CT$'
    automation:
      job_group: all
      deferred: true

  # Data sources for FI level 1
  - name: pipelines.epidemiology.fi_authority.FinlandArcGisDataSource
    fetch:
      - url: https://services7.arcgis.com/nuPvVz1HGGfa0Eh7/arcgis/rest/services/korona_tapauksia_jakauma/FeatureServer/0/query?f=json&where=1%3D1&outFields=OBJECTID,alue,date,tapauksia,miehia,naisia,Ika_0_9,ika_10_19,ika_20_29,ika_30_39,ika_40_49,ika_50_59,ika_60_69,ika_70_79,ika_80_,koodi&returnGeometry=false
        opts:
          ext: json
    query: "date > '2020-02-01'"
    test:
      location_key_match: '^FI$'
    automation:
      job_group: all
      deferred: true

  # Data sources for FR levels 1 + 2 + 3
  - name: pipelines.epidemiology.fr_authority.FranceStratifiedDataSource
    fetch:
      - url: https://dashboard.covid19.data.gouv.fr/data/code-{}.json
    test:
      location_key_match:
        - '^FR$'
        - '^FR_[^_]+$'
        - '^FR_[^_]+_[^_]+$'
    automation:
      job_group: all
      deferred: true

  # Data sources for HK level 0
  - name: pipelines.epidemiology.hk_authority.HongKongDataSource
    fetch:
      - url: "https://www.chp.gov.hk/files/misc/enhanced_sur_covid_19_eng.csv"
    parse:
      # This data source does not report zero values, so we fill them in
      fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      location_key_match: '^HK$'
    automation:
      job_group: all
      deferred: true

  # Data source for IN levels 0 + 1
  - name: pipelines.epidemiology.in_covid19india_org.Covid19IndiaOrgCasesDataSource
    fetch:
      - url: "https://api.covid19india.org/csv/latest/raw_data{idx}.csv"
        opts:
          ext: csv
    test:
      location_key_match:
        - '^IN$'
        - '^IN_[^_]+$'
    automation:
      job_group: all
      deferred: true

  # Data sources for MX levels 1, 2 and 3
  - name: pipelines.epidemiology.mx_authority.MexicoDataSource
    fetch:
      - url: "http://datosabiertos.salud.gob.mx/gobmx/salud/datos_abiertos/datos_abiertos_covid19.zip"
    parse:
      encoding: "ISO-8859-1"
      # This data source does not report zero values, so we fill them in
      fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      # Skip this data source because it's too slow
      skip: true
      location_key_match: 'MX_.+'
    automation:
      job_group: all
      deferred: true

  # Data sources for NZ level 0
  - name: pipelines.epidemiology.nz_authority.NewZealandDataSource
    fetch:
      - url: "https://www.health.govt.nz/system/files/documents/pages/covid_cases_{date}.csv"
        opts:
          date_format: '%Y-%m-%d'
    parse:
      # This data source does not report zero values, so we fill them in
      fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      location_key_match: '^NZ$'
      # Skip because it's flakey
      skip: true
    automation:
      job_group: all
      deferred: true

  # Data sources for PE levels 1 + 2 + 3
  - name: pipelines.epidemiology.pe_authority.PeruDataSource
    fetch:
      - name: confirmed
        url: "https://cloud.minsa.gob.pe/s/Y8w3wHsEdYQSZRp/download"
        opts:
          ext: csv
      - name: deceased
        url: "https://cloud.minsa.gob.pe/s/Md37cjXmjT9qYSa/download"
        opts:
          ext: csv
    parse:
      encoding: "ISO-8859-1"
      sep: ";"
    test:
      location_key_match: 'PE.*'
      # Skip because this is a flakey data source
      skip: true
    automation:
      job_group: all
      deferred: true

  # Data sources for PH levels 2 + 3
  # Mirrored from http://bit.ly/DataDropArchives
  - name: pipelines.epidemiology.ph_authority.PhilippinesDataSource
    fetch:
      - url: "https://storage.googleapis.com/finmango-covid-data/Philippines/Latest%20Case%20Information.csv"
        opts:
          ext: csv
    test:
      location_key_match: 'PH.*'
    automation:
      job_group: all
      deferred: true

  # Data sources for RO level 1
  - name: pipelines.epidemiology.ro_authority.RomaniaDataSource
    fetch:
      - url: "https://d35p9e4fm9h3wo.cloudfront.net/latestData.json"
    parse:
      skip_county: true
    test:
      location_key_match: '^RO$'
    automation:
      job_group: all
      deferred: true

  # Data sources for TH levels 0 + 1
  - name: pipelines.epidemiology.th_authority.ThailandCasesDataSource
    fetch:
      - url: "https://data.go.th/dataset/8a956917-436d-4afd-a2d4-59e4dd8e906e/resource/24ac8406-0cf9-4f8e-a55e-b53cf6766d1a/download/pm-covid19-adj.xlsx"
    parse:
      dtype: str
      # This data source does not report zero values, so we fill them in
      fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      location_key_match:
        - '^TH$'
        - '^TH_[^_]+$'
      # TODO: Fix broken data source (file has encoding issues)
      skip: true
    automation:
      job_group: all
      deferred: true

  # Data sources for TW levels 0 + 1
  - name: pipelines.epidemiology.tw_authority.TaiwanDataSource
    fetch:
      - url: "https://od.cdc.gov.tw/eic/Day_Confirmation_Age_County_Gender_19CoV.csv"
    parse:
      # This data source does not report zero values, so we fill them in
      fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      location_key_match:
        - '^TW$'
        - '^TW_[^_]+$'
      # Skip because it's too flakey
      skip: true
    automation:
      job_group: all
      deferred: true

  # Data sources for US level 2
  - name: pipelines.epidemiology.us_imperial.ImperialDataSource
    fetch:
      - url: "https://raw.githubusercontent.com/ImperialCollegeLondon/US-covid19-agespecific-mortality-data/master/data/processed/latest/DeathsByAge_US.csv"
    test:
      location_key_match: '^US_\w\w(_NYC)?$'
    automation:
      job_group: all
      deferred: true

  # Data sources for US_CA level 1
  - name: pipelines.epidemiology.us_ca_authority.CaliforniaOpenDataSource
    fetch:
      - url: "https://data.ca.gov/dataset/590188d5-8545-4c93-a9a0-e230f0db7290/resource/339d1c4d-77ab-44a2-9b40-745e64e335f2/download/case_demographics_age.csv"
    test:
      location_key_match: '^US_CA$'
    automation:
      job_group: all
      deferred: true

  - name: pipelines.epidemiology.us_ca_authority.CaliforniaCachedDataSource
    # No URL is given because it uses the cache
    fetch:
      - cache_key: US_CA-mortality-stratified
    test:
      location_key_match: '^US_CA$'
    automation:
      job_group: all
      deferred: true

  # Data sources for US_DC level 2
  - name: pipelines.epidemiology.us_dc_authority.DistrictColumbiaDataSource
    fetch:
      - url: "https://coronavirus.dc.gov/page/coronavirus-data"
        opts:
          ext: xlsx
    parse:
      sheet_name: "Lives Lost by Age"
    test:
      # Skip because it's too flakey
      skip: true
      location_key_match: '^US_DC$'
    automation:
      job_group: all
      deferred: true

  # Data sources for US_DE level 2
  - name: pipelines.epidemiology.us_de_authority.DelawareDataSource
    fetch:
      - url: "https://myhealthycommunity.dhss.delaware.gov/locations/state/download_covid_19_data"
        opts:
          ext: csv
          spoof_browser: false
    test:
      location_key_match: '^US_DE$'
      # Skip because endpoint fails frequently
      skip: true
    automation:
      job_group: all
      deferred: true

  # Data sources US_FL levels 1 + 2
  - name: pipelines.epidemiology.us_fl_authority.FloridaDataSource
    fetch:
      - url: "https://services1.arcgis.com/CY1LXxl9zlJeBuRZ/ArcGIS/rest/services/Florida_COVID19_Case_Line_Data_NEW/FeatureServer/0/query?where=1%3D1&outFields=*&f=json"
    parse:
      # This data source does not report zero values, so we fill them in
      fill_with_zeroes: ['new_[^_]+_age_.+']
    test:
      location_key_match:
        - '^US_FL$'
        - '^US_FL_[^_]+$'
      # Skip Florida because download takes a long time
      skip: true
    automation:
      job_group: all
      deferred: true

  # Data sources for US_GA levels 2 + 3
  - name: pipelines.epidemiology.us_ga_authority.GeorgiaStratifiedDataSource
    # No URL is given because it uses the cache
    fetch:
      - cache_key: US_GA_stratified
    parse:
      file_name: demographics_by_age_group.csv
      date_start: "2020-10-01"
    test:
      location_key_match: 'US_GA_.*'
    automation:
      job_group: all
      deferred: true

  # Data sources for US_IN level 3
  - name: pipelines.epidemiology.us_in_authority.IndianaDataSource
    fetch:
      - url: "https://hub.mph.in.gov/dataset/6b57a4f2-b754-4f79-a46b-cff93e37d851/resource/46b310b9-2f29-4a51-90dc-3886d9cf4ac1/download/covid_report.xlsx"
        opts:
          ext: xlsx
    # Only aggregate age/sex pipelines to state level because the data does not add up to the total
    # number of cases. This is because small case counts are excluded for privacy reasons.
    aggregate:
      subregion2: ['age_bin_*', 'new_confirmed_age_*']
    parse:
      # This data source does not report zero values, so we fill them in
      fill_with_zeroes: ['new_confirmed_age_*']
    test:
      location_key_match: 'US_IN.*'
    automation:
      job_group: all
      deferred: true

  # Data sources for US_MA level 3
  - name: pipelines.epidemiology.us_ma_authority.MassachusettsByAgeDataSource
    fetch:
      - name: by-age
        # August 11th was the last day US_MA reported cases broken down by age/sex
        url: "https://www.mass.gov/doc/covid-19-raw-data-august-11-2020/download"
        opts:
          ext: zip
    parse:
      file_name: Age.csv
    test:
      location_key_match: '^US_MA$'
    automation:
      job_group: all
      deferred: true

  # Data sources for US_WA level 2
  # Only present in by-age table because the data is not updated daily
  - name: pipelines.epidemiology.us_wa_authority.WashingtonDataSource
    fetch:
      - url: "https://www.doh.wa.gov/Portals/1/Documents/1600/coronavirus/data-tables/PUBLIC_CDC_Event_Date_SARS.xlsx"
    parse:
      sheet_name: ['Cases', 'Hospitalizations', 'Deaths']
    test:
      location_key_match:
        - '^US_WA+$'
        - '^US_WA_[^_]+$'
      # Skip testing because it's unreliable
      skip: true
    automation:
      job_group: all
      deferred: true
